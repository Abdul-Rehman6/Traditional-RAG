{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Standard library ---\n",
        "import os\n",
        "import re\n",
        "import operator\n",
        "from typing import TypedDict, Annotated, Literal, Sequence\n",
        "\n",
        "# --- LangGraph ---\n",
        "from langgraph.graph import StateGraph, START, END, add_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import tools_condition, ToolNode\n",
        "\n",
        "# --- LangChain Core ---\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# --- LangChain Community ---\n",
        "from langchain_community.document_loaders import ArxivLoader, PyMuPDFLoader, WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# --- LangChain OpenAI ---\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "# --- LangChain Tools ---\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "# --- LangChain Hub ---\n",
        "from langchain import hub\n",
        "\n",
        "# --- LangChain Text Splitters ---\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# --- Other third-party ---\n",
        "from pydantic import BaseModel, Field\n",
        "from dotenv import load_dotenv\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AsiwTZxn6Sh",
        "outputId": "a5603289-a786-4266-c1b0-c52147ab926d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An error occurred: \n",
            "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=7ARBJQn6QkM! This is most likely caused by:\n",
            "\n",
            "YouTube is blocking requests from your IP. This usually is due to one of the following reasons:\n",
            "- You have done too many requests and your IP has been blocked by YouTube\n",
            "- You are doing requests from an IP belonging to a cloud provider (like AWS, Google Cloud Platform, Azure, etc.). Unfortunately, most IPs from cloud providers are blocked by YouTube.\n",
            "\n",
            "There are two things you can do to work around this:\n",
            "1. Use proxies to hide your IP address, as explained in the \"Working around IP bans\" section of the README (https://github.com/jdepoix/youtube-transcript-api?tab=readme-ov-file#working-around-ip-bans-requestblocked-or-ipblocked-exception).\n",
            "2. (NOT RECOMMENDED) If you authenticate your requests using cookies, you will be able to continue doing requests for a while. However, YouTube will eventually permanently ban the account that you have used to authenticate with! So only do this if you don't mind your account being banned!\n",
            "\n",
            "If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\n"
          ]
        }
      ],
      "source": [
        "video_id = \"7ARBJQn6QkM\"\n",
        "\n",
        "try:\n",
        "    # Initialize the API\n",
        "    ytt_api = YouTubeTranscriptApi()\n",
        "\n",
        "    # Fetch the transcript\n",
        "    fetched_transcript = ytt_api.fetch(video_id, languages=['en'])\n",
        "\n",
        "    # Clean the transcript\n",
        "    transcript_text = \" \".join(snippet.text for snippet in fetched_transcript if snippet.text.strip() and not snippet.text.strip().startswith('['))\n",
        "    transcript_text = re.sub(r'[\\xa0\\n]+', ' ', transcript_text)  # Replace non-breaking spaces and newlines\n",
        "    transcript_text = re.sub(r'\\s+', ' ', transcript_text)  # Normalize whitespace\n",
        "    transcript_text = re.sub(r'\\[.*?\\]', '', transcript_text)  # Remove non-speech markers\n",
        "    transcript_text = transcript_text.strip()  # Remove leading/trailing spaces\n",
        "\n",
        "    print(\"Cleaned transcript (first 100 chars):\", transcript_text[:500] + \"...\")\n",
        "    print(\"Transcript length (chars):\", len(transcript_text))\n",
        "except TranscriptsDisabled:\n",
        "    print(\"Transcripts are disabled for this video.\")\n",
        "    transcript_text = \"\"\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "    transcript_text = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifQPJy-0n6Pr"
      },
      "outputs": [],
      "source": [
        "# fetched_transcript[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NACCcplxpnJa"
      },
      "outputs": [],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = splitter.create_documents([transcript_text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dut9qFamroFH",
        "outputId": "9fe04f32-5a9b-447f-d532-95486394ce7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8_Q6Egvrsgu"
      },
      "outputs": [],
      "source": [
        "# chunks[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "0uM2I1C4rx1J",
        "outputId": "36cf03cc-7e7f-4580-bc89-c6c17a24fc1d"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-238243376.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-3-small\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvectore_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/vectorstores/base.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \"\"\"\n\u001b[1;32m   1043\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m         return cls.__from(\n\u001b[0m\u001b[1;32m   1045\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36m__from\u001b[0;34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;31m# Default to L2, currently other metric types not initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexFlatL2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         \u001b[0mdocstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"docstore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInMemoryDocstore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0mindex_to_docstore_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"index_to_docstore_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "vectore_store = FAISS.from_documents(chunks, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qndrY1uGu7wK"
      },
      "outputs": [],
      "source": [
        "index_id = vectore_store.index_to_docstore_id[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9NPNLvmyEr7"
      },
      "outputs": [],
      "source": [
        "# vectore_store.get_by_ids([index_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyoL_1lFyQXR"
      },
      "outputs": [],
      "source": [
        "retriver = vectore_store.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNbXQ9wCyolW"
      },
      "outputs": [],
      "source": [
        "retriver #retriver is a runnable we ccan use invoke()\n",
        "#also it take the user query as input and returns the list of Documents in our case 4 documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM4Fsq3DzXbJ"
      },
      "outputs": [],
      "source": [
        "# output = retriver.invoke(\"what this podcast is about\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXb1xdxkzVk5"
      },
      "outputs": [],
      "source": [
        "# output[2].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cJhbta81sko"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UGZyzLO0NDe"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NO-MEHz71ni7"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "      You are a helpful assistant.\n",
        "      Answer ONLY from the provided transcript context.\n",
        "      If the context is insufficient, just say you Nothing about this is mentioned in the provided context.\n",
        "\n",
        "      {context}\n",
        "      Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables = ['context', 'question']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQo_7jdO2sou"
      },
      "outputs": [],
      "source": [
        "# question          = \"tell me about sam altman\"\n",
        "# retrieved_docs    = retriver.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3xq7BdA3VIj"
      },
      "outputs": [],
      "source": [
        "# retrieved_docs[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3D64Zpz3WRs"
      },
      "outputs": [],
      "source": [
        "# context_text = \" \".join(doc.page_content for doc in retrieved_docs)\n",
        "# context_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5iEmsJg8LtH"
      },
      "outputs": [],
      "source": [
        "# final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJRqVwzv9bNw"
      },
      "outputs": [],
      "source": [
        "# final_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjDDBIYr9eea"
      },
      "outputs": [],
      "source": [
        "# answer = llm.invoke(final_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpCaPCOe9kTY"
      },
      "outputs": [],
      "source": [
        "# answer.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3VJWtU_CFaJ"
      },
      "source": [
        "# **Chains**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Ej-zFc9mNR"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyOm_500Cdb_"
      },
      "outputs": [],
      "source": [
        "def format_docs(retrives_docs):\n",
        "  context_text = \" \".join(doc.page_content for doc in retrives_docs)\n",
        "  return context_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25NWEq_zCoW-"
      },
      "outputs": [],
      "source": [
        "parallel_chain = RunnableParallel({\n",
        "    'context': retriver | RunnableLambda(format_docs),\n",
        "    'question': RunnablePassthrough()\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1v1Kv_FDYwv"
      },
      "outputs": [],
      "source": [
        "# parallel_chain.invoke(\"what is gpt-5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aycnVH4LEBH-"
      },
      "outputs": [],
      "source": [
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9Gw3QSZDbRe"
      },
      "outputs": [],
      "source": [
        "main_chain = parallel_chain | prompt | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6X0P5ZGO38w"
      },
      "outputs": [],
      "source": [
        "# query_refinement_prompt = PromptTemplate(\n",
        "#     template=\"\"\"\n",
        "# You are helping rewrite vague questions to be clearer and more specific.\n",
        "\n",
        "# Context: The user is asking about a YouTube video transcript.\n",
        "# If possible, rewrite the question so that it's directly answerable, includes any important details or time references, and avoids ambiguity.\n",
        "\n",
        "# User Question: {original_question}\n",
        "\n",
        "# Refined Question:\n",
        "\n",
        "# \"\"\",\n",
        "#     input_variables=[\"original_question\"]\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GICw8gJuRh9l"
      },
      "outputs": [],
      "source": [
        "user_query = \"explain this video for me\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALCndXnUR3bS"
      },
      "outputs": [],
      "source": [
        "# llm_ready_query = query_refinement_prompt.invoke({'original_question':user_query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYrcc6eSSETQ"
      },
      "outputs": [],
      "source": [
        "# llm_ready_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Oj16wuAO3ju"
      },
      "outputs": [],
      "source": [
        "# refined_query = llm.invoke(llm_ready_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeudXwiKXAs8"
      },
      "outputs": [],
      "source": [
        "# refined_query.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDanvxkpD2Y9"
      },
      "outputs": [],
      "source": [
        "main_chain.invoke(user_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VUKeOI4D8UA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
